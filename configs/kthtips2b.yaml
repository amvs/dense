# model setting
wavelet: meyer
max_scale: 2
nb_orients: 4
share_channels: false
n_copies: 1
depth: -1  # -1 means full scatter
random: false
use_original_filters: false  # If true, use filters at different scales without downsampling. If false, use first filter and downsample (current mode).
use_log_transform: false  # If true, apply log(1+x) transform to scattering coefficients before classification

# classifier setting
classifier_type: hypernetwork
hypernet_hidden_dim: 64
attention_d_model: 128
attention_num_heads: 4
attention_num_layers: 2
pca_dim: 50  # Number of PCA components per class (used for 'pca', 'trainable_pca', 'lowrank_pca')
lowrank_pca_rank: 100  # Rank of shared basis for low-rank PCA (should be << feature_dim, typically 50-200)

# training setting
dataset: kthtips2b
kth_root_dir: data/datasets/KTH-TIPS2-b  # Path to KTH-TIPS2-b dataset root directory
resize: 200
fold: null  # Optional: 0-3 for leave-one-sample-out cross-validation, null for standard split
classifier_epochs: 1
conv_epochs: 1
batch_size: 32
lr: 0.05
linear_lr: 0.01
weight_decays: 1e-4
lambda_reg: 1.0e-4
fine_tune_mode: extractor_only  # Options: 'extractor_only' (freeze classifier, fine-tune extractor) or 'both' (fine-tune both together)
# Data size control (NEW: use example_per_class instead of train_ratio)
example_per_class: null  # Number of examples per class for training (null = use all available)
# train_ratio: 0.85  # DEPRECATED: Use example_per_class instead
test_ratio: 0.15  # Not used for KTH (test set is determined by fold or standard split)
train_val_ratio: 4  # Not used for KTH (val set is determined by fold or standard split)
use_balanced_batches: true  # Ensure each batch has equal examples per class
use_scale_augmentation: false  # If true, augment training images with scale factors [1, sqrt(2), 2, 2*sqrt(2)]
seed: 123

# dataset note
# classes=11, low rank pca rank < c*d*p/(d+c*p)
