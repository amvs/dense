{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets, transforms\n",
    "# from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "import torch\n",
    "from dense import dense\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# def get_mnist_loaders(batch_size=64, train_ratio=0.8):\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.1307,), (0.3081,))\n",
    "#     ])\n",
    "#     if train_ratio == 1.0:\n",
    "#         train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "#         test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "#         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "#     else:\n",
    "#         # Load both train and test parts of MNIST\n",
    "#         train_part = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "#         test_part = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "#         # Merge into one dataset\n",
    "#         full_dataset = ConcatDataset([train_part, test_part])\n",
    "\n",
    "#         # Extract all labels (ConcatDataset doesn't store `.targets` directly)\n",
    "#         targets = np.concatenate([np.array(train_part.targets), np.array(test_part.targets)])\n",
    "\n",
    "#         # Stratified split\n",
    "#         indices = np.arange(len(targets))\n",
    "#         train_indices, test_indices = train_test_split(\n",
    "#             indices,\n",
    "#             test_size=1-train_ratio,\n",
    "#             stratify=targets,\n",
    "#             random_state=42\n",
    "#         )\n",
    "\n",
    "#         # Create subsets\n",
    "#         train_dataset = Subset(full_dataset, train_indices)\n",
    "#         test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "#         # DataLoaders\n",
    "#         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     print(f\"[Ratio:{train_ratio}] Train size: {len(train_dataset)}, Test size: {len(test_dataset)}\")\n",
    "#     return train_loader, test_loader\n",
    "\n",
    "# def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     correct = 0\n",
    "#     for inputs, targets in loader:\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, targets) # Average loss in a batch\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item() * inputs.size(0) # Total loss in a batch\n",
    "#         correct += (outputs.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "#     avg_loss = total_loss / len(loader.dataset)\n",
    "#     accuracy = correct / len(loader.dataset) # Average loss\n",
    "#     return avg_loss, accuracy\n",
    "\n",
    "# def evaluate(model, loader, criterion, device):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, targets in loader:\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             total_loss += loss.item() * inputs.size(0)\n",
    "#             correct += (outputs.argmax(dim=1) == targets).sum().item()\n",
    "#     avg_loss = total_loss / len(loader.dataset)\n",
    "#     accuracy = correct / len(loader.dataset)\n",
    "#     return avg_loss, accuracy\n",
    "\n",
    "def run_mnist_experiment(scale_J, angle_K, kernel_size, model, train_ratio, image_shape=(1, 28), nb_class=10):\n",
    "    \n",
    "    train_loader, test_loader = get_mnist_loaders(batch_size=64, train_ratio=train_ratio)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(10):  # Change number of epochs as needed\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Test Acc={test_acc:.4f}\")\n",
    "    return test_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Train linear layer] Running: J=2, K=4, kernel=3, train_ratio=0.6\n",
      "Creating filter bank with Sampling support width=8, Size=3, Angles=4 ...\n",
      "Creating filter bank with Sampling support width=8, Size=5, Angles=4 ...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m     27\u001b[0m         param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m():\n\u001b[0;32m     29\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     30\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m run_mnist_experiment(J, K, ks, model, train_ratio)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to ../src and append it to sys.path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "\n",
    "models = []\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Try different combinations\n",
    "J_params = [2,3]\n",
    "K_params = [4,5]\n",
    "kernel_size_params = [3, 5, 7]\n",
    "train_ratios = [0.6,0.3, 0.1]\n",
    "##############################################\n",
    "# Train linear layer only\n",
    "results1 = []\n",
    "for J in J_params:\n",
    "    for K in K_params:\n",
    "        for ks in kernel_size_params:\n",
    "            for train_ratio in train_ratios:\n",
    "                print(f\"\\n[Train linear layer] Running: J={J}, K={K}, kernel={ks}, train_ratio={train_ratio}\")\n",
    "                model = dense(J, K, (1, 28), ks, nb_class=10).to(device)\n",
    "                for conv in model.sequential_conv:\n",
    "                    for param in conv.parameters():\n",
    "                        param.requires_grad = False\n",
    "                for param in model.linear.parameters():\n",
    "                    param.requires_grad = True\n",
    "                test_acc = run_mnist_experiment(J, K, ks, model, train_ratio)\n",
    "                config = f\"J={J}, K={K}, kernel={ks}, train_ratio={train_ratio}\"\n",
    "                results1.append((config, test_acc))\n",
    "                models.append(model)\n",
    "##############################################\n",
    "# Train conv layers only\n",
    "results2 = []\n",
    "count = 0\n",
    "result_models = []\n",
    "for J in J_params:\n",
    "        for K in K_params:\n",
    "            for ks in kernel_size_params:\n",
    "                for train_ratio in train_ratios:\n",
    "                    print(f\"\\n[Train conv layer] Running: J={J}, K={K}, kernel={ks}, train_ratio={train_ratio}\")\n",
    "                    model = models[count]\n",
    "                    for conv in model.sequential_conv:\n",
    "                        for param in conv.parameters():\n",
    "                            param.requires_grad = True\n",
    "                    for param in model.linear.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    config = f\"J={J}, K={K}, kernel={ks}, train_ratio={train_ratio}\"\n",
    "                    test_acc = run_mnist_experiment(J, K, ks, model, train_ratio)\n",
    "                    results2.append((config, test_acc))\n",
    "                    result_models.append(model)\n",
    "                    count = count+1\n",
    "# Print results summary\n",
    "print(model)\n",
    "for result1, result2 in zip(results1, results2):\n",
    "    config, acc1 = result1\n",
    "    _, acc2 = result2\n",
    "    print(f\"{config} â†’ Test Accuracy: {acc1:.2f}% {acc2:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scatter_net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
