# model setting
wavelet: morlet
max_scale: 6
nb_orients: 4
num_phases: 2
num_phases_prime: 1
random_filters: false
share_rotations: false
share_channels: true
share_phases: false
normalize_relu: true
delta_j: null
delta_l: null
shift_mode: samec
mask_union: false
mask_angles: 4
mask_union_highpass: true
share_scales: false
# downsample: false (full-size), true (spatial downsampled), 'hybrid' (mixed downsampling/upsampling)
downsample: true
# For hybrid mode, control signal downsampling per scale. Default: [j//2 for j in range(J)]
# Example: [0, 1, 2] means scales 0,1,2 get 2^0, 2^1, 2^2 signal downsampling
downsample_splits: null
share_scale_pairs: true
# wavelet_params:
#   S: 15 # S: 5 # S: 7 # 
#   sigma: 1.4
#   xi: 1.57 # xi: 2.356 # xi: 1.57 # xi: 0.75 * pi 
spatial_attn: false

# training setting
dataset: imbikramsaha/caltech-101
deeper_path: caltech-101
resize: 256
classifier_epochs: 15
conv_epochs: 15
batch_size: 16
lr: 0.0001
lr_conv: 1.0e-6 # verified good choice for downsample=true and false
lambda_reg: 1.0e+5
train_ratio: 0.1
test_ratio: 0.15
train_val_ratio: 2
seed: 42
vmap_chunk_size: 50
normalize_reg: false
ce_smooth: 0.1
model_type: wph
# Finetuning behavior
# If true (default), keep the classifier frozen during the feature-extractor finetuning stage.
freeze_classifier: true

# Classifier settings
num_classes: 101
use_batch_norm: true
copies: 1
noise_std: 0.01