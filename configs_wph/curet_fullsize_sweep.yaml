# This is a sweep config file for hyperparameter tuning on MNIST dataset
# It uses the base configuration from mnist.yaml and overrides specific parameters for the sweep
base_config: configs_wph/curet.yaml
sweep:
  classifier_epochs: [15]
  conv_epochs: [15]
  max_scale: [4]
  seed: [0]
  share_scale_pairs: [false]
  delta_j: [null]
  copies: [1]
  train_ratio: [0.5]
  lambda_reg: [0, 1.0e+4, 1.0e+6, 1.0e+8, 1.0e+10] # determined scale of lambda reg was 1e6
  downsample: [false]
  random_filters: [true, false]

