# Model settings
max_scale: 3
nb_orients: 4
num_phases: 4
num_phases_prime: 1
random_filters: false
share_rotations: false
share_channels: true
share_phases: false
share_scales: false
share_scale_pairs: true
normalize_relu: true
delta_j: null
delta_l: null
shift_mode: samec
mask_union: false
mask_angles: 4
mask_union_highpass: true
downsample: true
wavelet: morlet
wavelet_params:
  S: 7
  T: 8
  w0: 1.09955 # 0.35 * pi

# Training settings
dataset: mnist
classifier_epochs: 10
conv_epochs: 10
batch_size: 200
lr: 0.001
lr_conv: 1.0e-4
lambda_reg: 1.0e+3
test_ratio: 0.15
train_ratio: 0.85
train_val_ratio: 4
seed: 42
normalize_reg: false
# Finetuning behavior
# If true (default), keep the classifier frozen during the feature-extractor finetuning stage.
freeze_classifier: true

# Classifier settings
num_classes: 10
use_batch_norm: true
copies: 1
noise_std: 0.01

